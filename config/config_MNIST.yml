#parameters configuration
mode: train
root: data/
predefined_dataset: MNIST
classes: ["MNIST", "CIFAR10"]
max_samples: null
batch_size: 32
num_workers: 0
device: cuda
lr: 1e-3
in_chans: 3
input_height: 32
latent_dim: 256
generator_feature_dim: 64
discriminator_feature_dim: 64
checkpoint_path: null
seed: 0
early_stopping: True
patience: 3
default_root_dir: save/
gpus: -1
precision: 32
max_epochs: 100
color_space: RGB # (3x8-bit pixels, true color)
web_interface: True
examples:
  [
    "examples/MNIST/00000_7.png",
    "examples/MNIST/00001_2.png",
    "examples/MNIST/00002_1.png",
    "examples/MNIST/00003_0.png",
    "examples/MNIST/00004_4.png",
    "examples/MNIST/00007_9.png",
    "examples/MNIST/00011_6.png",
    "examples/MNIST/00061_8.png",
    "examples/MNIST/00433_5.png",
    "examples/MNIST/00449_3.png",
  ]
tuning_test: False
cpu_resources_per_trial: 1
gpu_resources_per_trial: 1
num_samples: 100

#transforms configuration
transforms_config:
  train:
    Resize:
      - 32
      - 32
    ToTensor:

  val:
    Resize:
      - 32
      - 32
    ToTensor:

  test:
    Resize:
      - 32
      - 32
    ToTensor:

  predict:
    Resize:
      - 32
      - 32
    ToTensor:

# target transforms configuration
target_transforms_config:
  train: null

  val: null

  test: null

  predict: null

# optimizers configuration
optimizers_config:
  Adam:
    betas:
      - 0.9
      - 0.999
    eps: 1e-08
    weight_decay: 0
    amsgrad: False

# learning rate schedulers configuration
lr_schedulers_config:
  CosineAnnealingLR:
    T_max: 10

# hyperparameter space configuration
hyperparameter_space_config:
  lr:
    uniform:
      lower: 1e-4
      upper: 1e-1

  max_epochs:
    randint:
      lower: 10
      upper: 200
